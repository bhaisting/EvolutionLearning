# GenerationLearning

This is a pet project I've worked on from Summer 2020 to Fall 2020 that tests evolution based learning on various systems. Each project uses a simlar framework but are run independently of eachother. At the baseline of each program is a generalizable neural network structure and the general idea of using evolution to train the system. Each simulation starts with a generation of neural networks that all compete to have the highest fitness. We then kill a certain percentage of the generation that have the lowest fitnesses and reproduce to refill for the next generation. Mutations in the reproduction phase allow the system to adjust and find new possible solutions to the problem its given, and over time with enough feeling around we arrive at a solution. The following three projects have been finished:

foodsurvivor - Starting at the middle of a 2 dimensional grid, neural networks are given their location and the location of food and need to learn to collect the food as efficiently as possible to survive as long as possible. Fitness is defined by how much food each survivor has eaten plus the manhattan distance from the end location to the food location normalized. After training, the system was able to successfully move efficiently to grab as much food as was physically possible from a round.

dicegame - In this simulation, we train a group of gamblers to play a dice game of risk vs reward. The rules are as follows: An N-sided dice is rolled and the value is added to a potential for that round. The gambler is then given a choice: they can roll again or take the potential to their total. If the gambler rolls again, they need to roll a number equal to or higher than their first roll to add that roll to their potential and not lose it. This new number becomes the new minumum needed value if the gambler tries to roll again. This continues until the gambler reaches a designated total. Fitness is defined by the number of turns it takes to reach the goal number such that the quicker a gambler reaches the goal, the higher the fitness of that gambler. The median fitness (score) of the gamblers after training was higher than the median score found when testing some of my friends and family.

othellogame - This simulation aims to create the best Othello player evolution can through a large and complicated hidden layer. This simulation had 64 inputs and 64 outputs, which made the computation time extremely long. To quantify the improvement of the generations over time, the system plays some of the best players from the generation against randomly generated neural networks that theoretically choose moves at random. This saw an improvement from a roughly ~50% win rate at the start to a maximum of 93% winrate after two days of running the program.
